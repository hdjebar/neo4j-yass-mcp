# Security Audit Findings - CRITICAL VULNERABILITIES

**Audit Date:** 2025-11-09
**Status:** âœ… **ALL CRITICAL/HIGH/MEDIUM/LOW FIXED** - All security vulnerabilities addressed
**Coverage:** 84.70% (414 tests passing)

---

## ðŸš¨ CRITICAL SEVERITY

### 1. âœ… **Query Execution Before Security Checks (CRITICAL - FIXED)**

**Location:** [server.py:442-614](src/neo4j_yass_mcp/server.py#L442-L614)

**Status:** âœ… **FIXED** in commit ee42290

**Vulnerability (ORIGINAL):**
```python
# Line 511: Chain executes query FIRST
result = await asyncio.to_thread(chain.invoke, {"query": query})

# Lines 527-587: THEN sanitization/complexity checks run
# BUT THE QUERY HAS ALREADY EXECUTED!
if generated_cypher and sanitizer_enabled:
    is_safe, sanitize_error, warnings = sanitize_query(generated_cypher, None)
```

**Impact:**
- âš ï¸ **COMPLETE SECURITY BYPASS** - Write operations, injections, and schema changes execute before ANY security check
- Attacker can use natural language to bypass sanitizer, complexity limiter, and read-only mode
- All "SISO prevention" is ineffective

**Attack Example:**
```python
# User input: "Delete all nodes"
# GraphCypherQAChain generates: "MATCH (n) DETACH DELETE n"
# Query EXECUTES and deletes everything
# THEN sanitizer checks it (too late!)
```

**Severity:** ðŸ”´ **CRITICAL** - Complete bypass of all security controls

**Fix Implemented:**
Created [SecureNeo4jGraph](src/neo4j_yass_mcp/secure_graph.py) wrapper that:
1. Inherits from `Neo4jGraph` and overrides `query()` method
2. Runs sanitization, complexity checks, and read-only validation BEFORE driver execution
3. Raises `ValueError` when security policies violated (query never executes)
4. Server now uses `SecureNeo4jGraph` instead of `Neo4jGraph`

**Verification:**
- Security checks now happen at graph level (lines 90-129 in secure_graph.py)
- All queries validated before reaching Neo4j driver
- Tests updated to verify ValueError raised on security failures
- No queries can bypass security controls

---

## ðŸ”´ HIGH SEVERITY

### 2. âœ… **Read-Only Mode Bypass via Whitespace/Procedures (HIGH - FIXED)**

**Location:** [server.py:129-177](src/neo4j_yass_mcp/server.py#L129-L177)

**Status:** âœ… **FIXED** - Regex-based validation with whitespace normalization

**Vulnerability (ORIGINAL):**
```python
def check_read_only_access(cypher: str) -> tuple[bool, str | None]:
    cypher_upper = cypher.upper()

    # Lines 137-141: Looks for " KEYWORD " with spaces
    for keyword in write_keywords:
        if f" {keyword} " in cypher_upper or cypher_upper.startswith(f"{keyword} "):
```

**Bypasses (ORIGINAL):**
```cypher
-- Works (detected):
MATCH (n) CREATE (m:Node) RETURN m

-- Bypasses (NOT detected):
CREATE\n(m:Node)              -- Newline after keyword
CREATE\t(m:Node)              -- Tab after keyword
CREATE(m:Node)                -- Parenthesis immediately after
CALL db.schema.nodeTypeProperties()  -- Mutating procedure
CALL apoc.write.create(...)   -- APOC write operation
LOAD CSV FROM 'file:///etc/passwd'   -- File access
FOREACH (x in [1,2] | CREATE ...)    -- Iteration with mutation
```

**Impact (ORIGINAL):**
- Read-only mode completely bypassable
- Schema manipulation possible
- File system access via LOAD CSV
- Batch operations via FOREACH

**Severity:** ðŸ”´ **HIGH** - Complete read-only bypass

**Fix Implemented:**
```python
def check_read_only_access(cypher_query: str) -> str | None:
    # Normalize whitespace (collapse tabs, newlines, multiple spaces)
    normalized = re.sub(r'\s+', ' ', cypher_query.strip()).upper()

    # Check FOREACH and LOAD CSV FIRST (contain write keywords)
    if re.search(r'\bFOREACH\b', normalized):
        return "Read-only mode: FOREACH not allowed"
    if re.search(r'\bLOAD\s+CSV\b', normalized):
        return "Read-only mode: LOAD CSV not allowed"

    # Check mutating procedures (before write keywords)
    mutating_procedures = [
        r'\bCALL\s+DB\.SCHEMA\.',
        r'\bCALL\s+APOC\.WRITE\.',
        r'\bCALL\s+APOC\.CREATE\.',
        r'\bCALL\s+APOC\.MERGE\.',
        r'\bCALL\s+APOC\.REFACTOR\.',
    ]
    for pattern in mutating_procedures:
        if re.search(pattern, normalized):
            return "Read-only mode: Mutating procedure not allowed"

    # Check write keywords using word boundaries
    write_keywords = ["CREATE", "MERGE", "DELETE", "REMOVE", "SET", "DETACH", "DROP"]
    for keyword in write_keywords:
        if re.search(rf'\b{keyword}\b', normalized):
            return f"Read-only mode: {keyword} operations are not allowed"

    return None
```

**Verification:**
- 30 comprehensive tests in [test_readonly_bypass_fixes.py](tests/unit/test_readonly_bypass_fixes.py)
- All bypass scenarios now blocked:
  - âœ… Whitespace bypass (newlines, tabs, multiple spaces)
  - âœ… No-space bypass (CREATE(node))
  - âœ… Mutating procedures (CALL apoc.write.*, CALL db.schema.*)
  - âœ… Dangerous operations (LOAD CSV, FOREACH)
  - âœ… Case insensitivity (create, DeLeTe)
- Valid read operations still allowed (MATCH, RETURN, UNWIND, WITH)
- Word boundary detection prevents false positives (n.created_at allowed)

---

## ðŸŸ  MEDIUM SEVERITY

### 3. âœ… **Global Rate Limiting Breaks Per-Session Enforcement (MEDIUM - FIXED)**

**Location:** [server.py:137-160](src/neo4j_yass_mcp/server.py#L137-L160)

**Status:** âœ… **FIXED** - Stable per-session client ID tracking implemented

**Vulnerability (ORIGINAL):**
```python
# Line 569: Hard-coded client_id
is_allowed, rate_info = check_rate_limit(client_id="default")

# Line 759: Same hard-coded value
is_allowed, rate_info = check_rate_limit(client_id="default")
```

**Impact (ORIGINAL):**
- One noisy client blocks ALL clients
- No way to identify which client exceeded quota
- Audit trail useless for forensics
- Denial of Service trivial

**REGRESSION (Intermediate Fix Attempt):**
The initial fix generated a NEW client_id for EVERY request, which completely disabled rate limiting:
- Each request got a fresh rate limit bucket with full tokens
- Rate limiting never triggered
- This was worse than the original bug

**Severity:** ðŸŸ  **MEDIUM** - DoS and forensics impact

**Fix Implemented (CORRECT):**
```python
# Lines 133-135: Context-based client ID tracking
_current_client_id: contextvars.ContextVar[str] = contextvars.ContextVar(
    "current_client_id"  # NO default - force LookupError on first access
)

# Lines 137-160: Stable session-based client ID
def get_client_id() -> str:
    """
    Get stable client ID for the current MCP session.

    Uses the async task ID as a stable session identifier so that all requests
    from the same MCP client/session share the same rate limit bucket. This
    enables per-session rate limiting where the rate limit is enforced across
    multiple requests from the same client.

    Each MCP client connection runs in its own async task, so the task ID
    provides a stable, unique identifier for the session lifetime.
    """
    try:
        # Return existing client ID if already set for this session
        return _current_client_id.get()
    except LookupError:
        # First request in this session - generate stable ID from task
        # This ID will be reused for all subsequent requests in same session
        client_id = f"session_{id(asyncio.current_task())}"
        _current_client_id.set(client_id)
        return client_id
```

**Verification:**
- Each MCP session gets ONE stable client_id
- All requests from same session share the same rate limit bucket
- Rate limiting is properly enforced across multiple requests
- Different sessions get different client_ids
- Tests added:
  - `test_sequential_requests_share_same_client_id`: Verifies 3 sequential requests in same session share same ID
  - `test_rate_limiting_actually_blocks_after_limit`: Verifies rate limiting actually blocks after 5 requests (REAL functionality test)
- Test suite: 415 tests passing

**Empirical Test Results (FINAL FIX):**
```python
# Sequential requests in same session:
Request 1: session_4436984240  # Generated on first request
Request 2: session_4436984240  # REUSED (same session!)
Request 3: session_4436984240  # REUSED (same session!)
All same? True âœ…

# Rate limiting actually works:
Requests 1-5: SUCCESS (within burst limit)
Request 6: BLOCKED (rate_limited=True, retry_after_seconds=60)
Request 7: BLOCKED (rate_limited=True) âœ…
```

---

### 4. âœ… **Error Message Sanitization Case Sensitivity Bug (MEDIUM - FIXED)**

**Location:** [server.py:215-259](src/neo4j_yass_mcp/server.py#L215-L259)

**Status:** âœ… **FIXED** - All safe patterns converted to lowercase

**Vulnerability (ORIGINAL):**
```python
def sanitize_error_message(error: Exception) -> str:
    error_str = str(error)
    error_lower = error_str.lower()  # Line 252

    # Lines 241-250: Compares MIXED-CASE patterns against lowercase string
    safe_patterns = [
        "authentication failed",
        "Connection refused",    # <-- This never matches!
        "Query Exceeds Maximum Length",  # <-- Never matches!
        "timeout",
        # ... etc
    ]

    for pattern in safe_patterns:
        if pattern in error_lower:  # "Connection refused" != "connection refused"
```

**Impact (ORIGINAL):**
- Most error messages reduced to useless "<Type>: An error occurred..."
- Debugging and operations significantly harder
- May leak sensitive info in unhandled cases

**Severity:** ðŸŸ  **MEDIUM** - Operations impact

**Fix Implemented:**
```python
# Lines 240-251: All patterns now lowercase for case-insensitive matching
safe_patterns = [
    "query exceeds maximum length",  # Fixed - was mixed case
    "empty query not allowed",  # Fixed - was mixed case
    "blocked: query contains dangerous pattern",  # Fixed - was mixed case
    "authentication failed",
    "connection refused",  # Fixed - was "Connection refused"
    "timeout",
    "not found",
    "unauthorized",
]
```

**Verification:**
- 19 comprehensive tests in [test_error_sanitization_fix.py](tests/unit/test_error_sanitization_fix.py)
- Tests cover all case variations (lowercase, UPPERCASE, Title Case, MiXeD)
- Verified patterns now match regardless of error message casing
- Test suite: 409 tests passing (82.65% coverage)

---

### 5. âœ… **SecureNeo4jGraph Untested (MEDIUM - FIXED)**

**Location:** [secure_graph.py](src/neo4j_yass_mcp/secure_graph.py)

**Status:** âœ… **FIXED** - Comprehensive tests added for all security layers

**Vulnerability (ORIGINAL):**
- SecureNeo4jGraph coverage: 18% (36/44 lines missed)
- Critical security checks not exercised by tests
- No verification that security blocks queries before execution
- Could introduce regressions without detection

**Impact (ORIGINAL):**
- Security bugs could be introduced undetected
- No validation that queries are blocked BEFORE execution
- Coverage gaps in critical security path

**Severity:** ðŸŸ  **MEDIUM** - Test coverage and security validation

**Fix Implemented:**
Created comprehensive test suite [test_secure_graph.py](tests/unit/test_secure_graph.py) with 20 tests covering:

1. **Sanitization Tests (6 tests)**:
   - LOAD CSV file access blocking
   - String concatenation injection blocking
   - Query chaining with semicolons
   - Dangerous APOC procedures (apoc.load, apoc.cypher.run, apoc.periodic.iterate)
   - Unicode homoglyph detection
   - Safe query validation

2. **Complexity Tests (2 tests)**:
   - Unbounded variable-length patterns (5 patterns = 125 score > 100 limit)
   - Simple query validation

3. **Read-Only Mode Tests (4 tests)**:
   - CREATE, MERGE, DELETE, SET blocking
   - Whitespace bypass prevention (newlines, tabs, no-space)
   - Mutating procedures (CALL apoc.write.*, CALL db.schema.*)
   - Safe read queries (MATCH, CALL db.labels, UNWIND)

4. **Layered Security Tests (3 tests)**:
   - Sanitizer catches malicious patterns
   - Complexity limiter catches complex queries
   - Read-only mode catches write operations

5. **Configuration Tests (2 tests)**:
   - Independent security function validation
   - Safe queries pass all checks

**Verification:**
- 24 comprehensive tests (4 interception + 20 security function tests)
- **Interception tests** mock parent Neo4jGraph.query() and verify:
  - Parent is NOT called when security checks fail
  - Parent IS called when security checks pass
  - Proves SecureNeo4jGraph intercepts queries BEFORE execution
- **Security function tests** validate sanitizer, complexity, read-only logic
- Coverage improved: SecureNeo4jGraph 18% â†’ 73%, Overall 82.16% â†’ 84.74%
- Test suite: 413 tests passing (all pass)

---

## ðŸŸ¡ LOW SEVERITY

### 6. âœ… **Response Truncation Only Applies to intermediate_steps (LOW - FIXED)**

**Location:** [server.py:562-584](src/neo4j_yass_mcp/server.py#L562-L584)

**Status:** âœ… **FIXED** - Both intermediate_steps and answer now truncated

**Vulnerability (ORIGINAL):**
```python
# Only truncates intermediate_steps
truncated_steps, was_truncated = truncate_response(result.get("intermediate_steps", []))

response = {
    "answer": result.get("result", ""),  # NOT truncated!
    "intermediate_steps": truncated_steps,
}
```

**Impact (ORIGINAL):**
- Large result strings bypass token limit
- Could cause memory issues or slow responses
- Token budgeting ineffective

**Severity:** ðŸŸ¡ **LOW** - Resource management

**Fix Implemented:**
```python
# Lines 562-584: Truncate BOTH intermediate steps AND final answer
truncated_steps, steps_truncated = truncate_response(result.get("intermediate_steps", []))
truncated_answer, answer_truncated = truncate_response(result.get("result", ""))

was_truncated = steps_truncated or answer_truncated

response = {
    "answer": truncated_answer,  # Now truncated!
    "intermediate_steps": truncated_steps,
}

if was_truncated:
    truncation_parts = []
    if steps_truncated:
        truncation_parts.append("intermediate steps")
    if answer_truncated:
        truncation_parts.append("answer")
    response["warning"] = f"Response truncated ({', '.join(truncation_parts)}) due to size limits"
```

**Verification:**
- Answer field now truncated when exceeding token limit
- Warning message specifies which parts were truncated
- Test suite: 388/389 passing (84.14% coverage)

---

### 7. âœ… **Runtime HuggingFace Download Failures (LOW - FIXED)**

**Location:** [server.py:191-235](src/neo4j_yass_mcp/server.py#L191-L235)

**Status:** âœ… **FIXED** - Multi-backend tokenizer with graceful degradation

**Vulnerability (ORIGINAL):**
```python
def get_tokenizer():
    try:
        from transformers import GPT2TokenizerFast
        return GPT2TokenizerFast.from_pretrained("gpt2")  # Network download!
```

**Impact (ORIGINAL):**
- Fails in air-gapped/restricted environments
- httpx logging errors in tests
- Server startup could fail

**Severity:** ðŸŸ¡ **LOW** - Reliability

**Fix Implemented:**
```python
# Lines 27-38: Try tiktoken first, then tokenizers, then fallback
try:
    import tiktoken
    TOKENIZER_BACKEND = "tiktoken"
except ImportError:
    tiktoken = None
    try:
        from tokenizers import Tokenizer
        TOKENIZER_BACKEND = "tokenizers"
    except ImportError:
        Tokenizer = None
        TOKENIZER_BACKEND = "fallback"

# Lines 191-235: Multi-backend tokenizer initialization
def get_tokenizer() -> Any:
    """
    Get or create tokenizer for token estimation.

    Tries multiple backends in order of preference:
    1. tiktoken (fast, no download needed)
    2. tokenizers with local_files_only (no network call)
    3. None (graceful degradation to character-based estimation)
    """
    global _tokenizer
    if _tokenizer is None:
        # Try tiktoken first (no download needed)
        if tiktoken is not None:
            try:
                _tokenizer = tiktoken.get_encoding("gpt2")
                return _tokenizer
            except Exception as e:
                logger.warning(f"tiktoken failed: {e}, trying next backend")

        # Fall back to tokenizers with local cache only
        if Tokenizer is not None:
            try:
                _tokenizer = Tokenizer.from_pretrained("gpt2", local_files_only=True)
                return _tokenizer
            except Exception as e:
                logger.warning(f"Tokenizer failed: {e}. Using fallback estimation.")
                _tokenizer = None  # Will use fallback estimation

    return _tokenizer

# Lines 238-271: Handle None tokenizer in estimate_tokens()
def estimate_tokens(text: str) -> int:
    tokenizer = get_tokenizer()

    if tokenizer is None:
        # Fallback: estimate 4 characters per token
        return len(text) // 4

    # Handle tiktoken backend
    if TOKENIZER_BACKEND == "tiktoken":
        return len(tokenizer.encode(text))

    # Handle tokenizers backend
    if TOKENIZER_BACKEND == "tokenizers":
        encoding = tokenizer.encode(text)
        return len(encoding.ids)

    # Fallback
    return len(text) // 4
```

**Verification:**
- Server now uses tiktoken (no download required) as primary backend
- Falls back to tokenizers with `local_files_only=True` (no network call)
- Graceful degradation to character-based estimation (4 chars per token)
- Works in air-gapped environments without network access
- Test suite: 388/389 passing (82.38% coverage)

---

## ðŸ“Š Summary

| Severity | Count | Status |
|----------|-------|--------|
| âœ… CRITICAL | 1 | **FIXED** - SecureNeo4jGraph implemented |
| âœ… HIGH | 1 | **FIXED** - Read-only bypass fixed with regex validation |
| âœ… MEDIUM | 3 | **ALL FIXED** - Rate limiting + Error sanitization + SecureNeo4jGraph tests |
| âœ… LOW | 2 | **ALL FIXED** - Response truncation + Multi-backend tokenizer |

## ðŸŽ¯ Actions Completed

1. âœ… **Issue #1 FIXED** - `SecureNeo4jGraph` wrapper implemented with pre-execution validation
2. âœ… **Issue #2 FIXED** - Read-only mode bypass fixed with regex-based validation + 30 tests
3. âœ… **Issue #3 FIXED** - Per-request rate limiting with unique client IDs per tool invocation + test
4. âœ… **Issue #4 FIXED** - Error message sanitization case sensitivity fixed + 19 tests
5. âœ… **Issue #5 FIXED** - SecureNeo4jGraph comprehensive test coverage added + 24 tests
6. âœ… **Issue #6 FIXED** - Response truncation now applies to both intermediate_steps AND answer
7. âœ… **Issue #7 FIXED** - Multi-backend tokenizer with graceful degradation (tiktoken â†’ tokenizers â†’ fallback)

## ðŸ”§ Refactoring Recommendations

1. âœ… **Extract `SecureNeo4jGraph` wrapper** - COMPLETED - All security checks now run before query execution
2. **Split server.py** - 1000+ lines is unmaintainable; separate transport, tools, and utilities
3. **Configuration injection** - Make tokenizer, limits, and security configurable without code changes
4. **Remove unused code** - `get_executor()` is defined but never used

---

**Next Steps:**
1. Create GitHub issues for each vulnerability
2. Prioritize CRITICAL and HIGH fixes
3. Write regression tests for each fix
4. Update security documentation
